# AnÃ¡lise PCA + K-Means no Dataset MNIST ğŸ”¢

AnÃ¡lise completa de clustering aplicando PCA (Principal Component Analysis) e K-Means no dataset MNIST de dÃ­gitos manuscritos.

## ğŸ“‹ Sobre o Projeto

Este projeto demonstra tÃ©cnicas de aprendizado nÃ£o supervisionado para agrupar dÃ­gitos manuscritos do dataset MNIST. Utilizamos reduÃ§Ã£o dimensional com PCA e clustering com K-Means, comparando diferentes configuraÃ§Ãµes e avaliando os resultados com mÃºltiplas mÃ©tricas. 

### Objetivos

- âœ… Aplicar PCA com diferentes nÃºmeros de componentes (2, 10, 30)
- âœ… Realizar clustering com K-Means (k=10 clusters)
- âœ… Avaliar qualidade dos clusters com Silhouette Score, ARI e NMI
- âœ… Comparar performance entre configuraÃ§Ãµes
- âœ… Gerar 7 visualizaÃ§Ãµes detalhadas para interpretaÃ§Ã£o
- âœ… Identificar padrÃµes e limitaÃ§Ãµes do mÃ©todo

---

## ğŸš€ Como Rodar no Jupyter Notebook

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)
- Jupyter Notebook ou JupyterLab

### Passo 1: Clone ou Baixe o RepositÃ³rio

**OpÃ§Ã£o A: Clonar via Git**
```bash
git clone https://github.com/tavs-coelho/slide-4.git
cd slide-4
```

**OpÃ§Ã£o B: Baixar ZIP**
1. VÃ¡ para https://github.com/tavs-coelho/slide-4
2. Clique em "Code" â†’ "Download ZIP"
3. Extraia o arquivo e navegue atÃ© a pasta no terminal

### Passo 2: Criar Ambiente Virtual (Recomendado)

**No Windows:**
```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
venv\Scripts\activate
```

**No Linux/Mac:**
```bash
# Criar ambiente virtual
python3 -m venv venv

# Ativar ambiente virtual
source venv/bin/activate
```

VocÃª verÃ¡ `(venv)` no inÃ­cio da linha do terminal quando o ambiente estiver ativado.

### Passo 3: Instalar DependÃªncias

Com o ambiente virtual ativado, instale todas as bibliotecas necessÃ¡rias:

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

**Pacotes que serÃ£o instalados:**
- `scikit-learn` - Algoritmos de ML (PCA, K-Means, mÃ©tricas)
- `matplotlib` - VisualizaÃ§Ãµes
- `seaborn` - GrÃ¡ficos estatÃ­sticos
- `pandas` - ManipulaÃ§Ã£o de dados
- `numpy` - OperaÃ§Ãµes numÃ©ricas
- `jupyter` - Ambiente de notebooks
- `notebook` - Interface Jupyter Notebook

â±ï¸ **Tempo estimado:** 2-5 minutos (dependendo da conexÃ£o)

### Passo 4: Iniciar o Jupyter Notebook

```bash
jupyter notebook
```

Isso irÃ¡:
1. Iniciar o servidor Jupyter
2. Abrir automaticamente seu navegador em `http://localhost:8888`
3. Mostrar a lista de arquivos do diretÃ³rio

**Alternativa - JupyterLab (interface mais moderna):**
```bash
jupyter lab
```

### Passo 5: Abrir o Notebook de AnÃ¡lise

Na interface do Jupyter:
1. Clique em `mnist_analysis.ipynb`
2. O notebook serÃ¡ aberto em uma nova aba

### Passo 6: Executar o Notebook

**OpÃ§Ã£o A: Executar Todas as CÃ©lulas de Uma Vez**
1. No menu superior, clique em **Cell** â†’ **Run All**
2. Aguarde a execuÃ§Ã£o completa (â±ï¸ ~5-10 minutos)
3. VisualizaÃ§Ãµes aparecerÃ£o inline e serÃ£o salvas em `results/`

**OpÃ§Ã£o B: Executar CÃ©lula por CÃ©lula (Recomendado para Primeira ExecuÃ§Ã£o)**
1. Clique na primeira cÃ©lula
2. Pressione **Shift + Enter** para executar e avanÃ§ar
3. Observe os outputs e grÃ¡ficos
4. Leia as explicaÃ§Ãµes em markdown entre as cÃ©lulas
5. Continue atÃ© a Ãºltima cÃ©lula

**Atalhos Ãšteis:**
- `Shift + Enter` - Executar cÃ©lula atual e avanÃ§ar
- `Ctrl + Enter` - Executar cÃ©lula atual (sem avanÃ§ar)
- `Alt + Enter` - Executar cÃ©lula e inserir nova abaixo
- `Esc` - Modo comando (navegar entre cÃ©lulas)
- `Enter` - Modo ediÃ§Ã£o (editar cÃ©lula)

### Passo 7: Verificar Resultados

ApÃ³s a execuÃ§Ã£o completa:

**VisualizaÃ§Ãµes Inline:**
- GrÃ¡ficos aparecerÃ£o diretamente no notebook

**Arquivos Salvos:**
```bash
results/
â”œâ”€â”€ mnist_samples.png              # Exemplos do dataset
â”œâ”€â”€ variance_explained.png         # VariÃ¢ncia explicada por PCA
â”œâ”€â”€ clusters_2d_predicted.png      # Clusters preditos em 2D
â”œâ”€â”€ clusters_2d_true.png           # Labels verdadeiros em 2D
â”œâ”€â”€ confusion_matrices.png         # Matrizes de confusÃ£o (2, 10, 30 comp.)
â”œâ”€â”€ metrics_comparison.png         # ComparaÃ§Ã£o de mÃ©tricas
â”œâ”€â”€ cluster_samples.png            # Exemplos de dÃ­gitos por cluster
â””â”€â”€ elbow_method.png               # MÃ©todo do cotovelo para K
```

**MÃ©tricas no Notebook:**
- Tabela comparativa de Silhouette Score, ARI, NMI
- AnÃ¡lises textuais e interpretaÃ§Ãµes

---

## ğŸ“‚ Estrutura do Projeto

```
slide-4/
â”œâ”€â”€ README.md                      # ğŸ“– Este arquivo - DocumentaÃ§Ã£o completa
â”œâ”€â”€ requirements.txt               # ğŸ“¦ DependÃªncias Python
â”œâ”€â”€ mnist_analysis.ipynb           # ğŸ““ Notebook principal com anÃ¡lise
â”œâ”€â”€ .gitignore                     # ğŸš« Arquivos ignorados pelo Git
â””â”€â”€ results/                       # ğŸ“Š Pasta gerada com visualizaÃ§Ãµes
    â”œâ”€â”€ mnist_samples.png
    â”œâ”€â”€ variance_explained.png
    â”œâ”€â”€ clusters_2d_predicted.png
    â”œâ”€â”€ clusters_2d_true.png
    â”œâ”€â”€ confusion_matrices.png
    â”œâ”€â”€ metrics_comparison.png
    â”œâ”€â”€ cluster_samples.png
    â””â”€â”€ elbow_method.png
```

---

## ğŸ”§ SoluÃ§Ã£o de Problemas

### Problema: `ModuleNotFoundError: No module named 'sklearn'`

**SoluÃ§Ã£o:**
```bash
pip install scikit-learn
```

### Problema: `Jupyter command not found`

**SoluÃ§Ã£o:**
```bash
pip install jupyter notebook
```

### Problema: Kernel morto ou travado

**SoluÃ§Ã£o:**
1. No menu: **Kernel** â†’ **Restart & Clear Output**
2. Execute novamente: **Cell** â†’ **Run All**

### Problema: Demora muito para baixar MNIST

**SoluÃ§Ã£o:**
O dataset MNIST (~55MB) Ã© baixado automaticamente na primeira execuÃ§Ã£o. Se houver problemas:
```python
# Na cÃ©lula de carregamento, adicione timeout:
mnist = fetch_openml('mnist_784', version=1, as_frame=False, 
                     parser='auto', timeout=120)
```

### Problema: MemÃ³ria insuficiente

**SoluÃ§Ã£o:**
O notebook usa um subset de 10.000 amostras por padrÃ£o. Se ainda assim houver problemas:
```python
# Reduza ainda mais o subset:
subset_size = 5000  # Em vez de 10000
```

### Problema: VisualizaÃ§Ãµes nÃ£o aparecem

**SoluÃ§Ã£o:**
```python
# Adicione no inÃ­cio do notebook:
%matplotlib inline
```

---

## âš™ï¸ ConfiguraÃ§Ãµes Opcionais

### Usar Dataset Completo (70k amostras)

No notebook, na seÃ§Ã£o "2. Carregamento e PreparaÃ§Ã£o dos Dados", comente estas linhas:

```python
# Comentar para usar dataset completo:
# subset_size = 10000
# indices = np.random.RandomState(42).choice(len(X), subset_size, replace=False)
# X = X[indices]
# y = y[indices]
```

âš ï¸ **AtenÃ§Ã£o:** ExecuÃ§Ã£o levarÃ¡ ~30-60 minutos

### Ajustar NÃºmero de Componentes PCA

Na seÃ§Ã£o "4. PCA + K-Means", modifique:

```python
# Testar outras configuraÃ§Ãµes:
n_components_list = [2, 5, 10, 20, 30, 50]
```

### Mudar NÃºmero de Clusters

```python
# Testar outros valores de k:
n_clusters = 15  # Em vez de 10
```

---

## ğŸ“Š Resultados Esperados

### Tabela de MÃ©tricas (valores aproximados)

| PCA Components | Silhouette Score | ARI   | NMI   | VariÃ¢ncia Explicada |
|----------------|------------------|-------|-------|---------------------|
| 2              | ~0.25            | ~0.45 | ~0.50 | ~25%                |
| 10             | ~0.17            | ~0.58 | ~0.63 | ~60%                |
| 30             | ~0.15            | ~0.65 | ~0.68 | ~85%                |

### Principais Insights

âœ… **PCA com 30 componentes** oferece melhor concordÃ¢ncia com labels verdadeiros

âœ… **PCA com 2 componentes** tem melhor Silhouette Score (clusters mais separados geometricamente)

âš ï¸ **DÃ­gitos confundidos:** 4â†”9, 3â†”5, 7â†”1 sÃ£o frequentemente agrupados juntos

âš ï¸ **LimitaÃ§Ã£o do K-Means:** Assume clusters esfÃ©ricos, nÃ£o ideal para formas complexas

---

## ğŸ“š ExplicaÃ§Ã£o dos Conceitos

### O que Ã© PCA?

**Principal Component Analysis (PCA)** Ã© uma tÃ©cnica de reduÃ§Ã£o dimensional que:
- Transforma dados de alta dimensÃ£o (784 pixels) para baixa dimensÃ£o (2, 10, 30)
- Preserva a mÃ¡xima variÃ¢ncia possÃ­vel
- Remove redundÃ¢ncia e ruÃ­do

**Por que usar?**
- Reduz custo computacional
- Facilita visualizaÃ§Ã£o (2D, 3D)
- Remove features correlacionadas

### O que Ã© K-Means?

**K-Means** Ã© um algoritmo de clustering que:
- Agrupa dados em K clusters
- Minimiza a distÃ¢ncia intra-cluster
- Atribui cada ponto ao centroide mais prÃ³ximo

**Como funciona?**
1. Inicializa K centroides aleatÃ³rios
2. Atribui cada ponto ao centroide mais prÃ³ximo
3. Recalcula centroides como mÃ©dia dos pontos
4. Repete 2-3 atÃ© convergÃªncia

### MÃ©tricas de AvaliaÃ§Ã£o

#### Silhouette Score (-1 a 1)
- Mede coesÃ£o intra-cluster e separaÃ§Ã£o inter-cluster
- **> 0.7**: Clustering excelente
- **0.5-0.7**: Clustering razoÃ¡vel
- **< 0.5**: Clustering fraco
- **< 0**: Pontos podem estar no cluster errado

#### Adjusted Rand Index (0 a 1)
- Compara clusters preditos vs labels verdadeiros
- **1.0**: ConcordÃ¢ncia perfeita
- **0.0**: ConcordÃ¢ncia ao acaso
- Ajustado por chance (melhor que Rand Index simples)

#### Normalized Mutual Information (0 a 1)
- Mede informaÃ§Ã£o mÃºtua entre clusters e labels
- **1.0**: InformaÃ§Ã£o compartilhada perfeita
- **0.0**: Sem informaÃ§Ã£o compartilhada
- Independente do nÃºmero de clusters

---

## ğŸ¯ Casos de Uso

Este projeto pode ser adaptado para:

- ğŸ“ **Reconhecimento de caracteres manuscritos**
- ğŸ·ï¸ **SegmentaÃ§Ã£o de clientes** (substituir MNIST por dados de clientes)
- ğŸ–¼ï¸ **CompressÃ£o de imagens** (PCA como autoencoder linear)
- ğŸ” **DetecÃ§Ã£o de anomalias** (pontos distantes de todos os clusters)
- ğŸ“Š **AnÃ¡lise exploratÃ³ria** de datasets de alta dimensÃ£o

---

## ğŸ› ï¸ Tecnologias Utilizadas

| Tecnologia | VersÃ£o | Uso |
|------------|--------|-----|
| Python | 3.8+ | Linguagem principal |
| scikit-learn | 1.3.0+ | Algoritmos de ML (PCA, K-Means, mÃ©tricas) |
| matplotlib | 3.7.0+ | VisualizaÃ§Ãµes |
| seaborn | 0.12.0+ | GrÃ¡ficos estatÃ­sticos |
| pandas | 2.0.0+ | ManipulaÃ§Ã£o de dados |
| numpy | 1.24.0+ | OperaÃ§Ãµes numÃ©ricas |
| jupyter | 1.0.0+ | Ambiente de notebooks |

---

## ğŸ“– ReferÃªncias e Leituras Recomendadas

### Papers Fundamentais
- **PCA:** Pearson, K. (1901). "On Lines and Planes of Closest Fit to Systems of Points in Space"
- **K-Means:** MacQueen, J. (1967). "Some methods for classification and analysis of multivariate observations"

### Tutoriais Online
- [Scikit-learn PCA Documentation](https://scikit-learn.org/stable/modules/decomposition.html#pca)
- [Scikit-learn K-Means Documentation](https://scikit-learn.org/stable/modules/clustering.html#k-means)
- [Understanding PCA - StatQuest](https://www.youtube.com/watch?v=FgakZw6K1QQ)
- [K-Means Clustering - StatQuest](https://www.youtube.com/watch?v=4b5d3muPQmA)

### Livros
- "Python Machine Learning" - Sebastian Raschka
- "Hands-On Machine Learning" - AurÃ©lien GÃ©ron
- "Pattern Recognition and Machine Learning" - Christopher Bishop

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature (`git checkout -b feature/NovaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona NovaFeature'`)
4. Push para a branch (`git push origin feature/NovaFeature`)
5. Abra um Pull Request

### Ideias para ContribuiÃ§Ãµes

- ğŸ”„ Adicionar outros algoritmos (DBSCAN, GMM, Hierarchical)
- ğŸ“Š Implementar t-SNE e UMAP para visualizaÃ§Ã£o
- ğŸ§ª Experimentar com datasets diferentes (Fashion-MNIST, CIFAR-10)
- ğŸ“ˆ Adicionar anÃ¡lise de sensibilidade dos hiperparÃ¢metros
- ğŸ¨ Melhorar visualizaÃ§Ãµes com Plotly interativo
- ğŸ“ Adicionar testes unitÃ¡rios

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

## ğŸ‘¤ Autor

**Tavs Coelho**

- GitHub: [@tavs-coelho](https://github.com/tavs-coelho)
- RepositÃ³rio: [slide-4](https://github.com/tavs-coelho/slide-4)

---

## ğŸ™ Agradecimentos

- Dataset MNIST original: Yann LeCun, Corinna Cortes, Christopher J. C. Burges
- Scikit-learn contributors
- Jupyter Project
- Comunidade Python de Machine Learning

---

## â“ FAQ (Perguntas Frequentes)

### P: Quanto tempo leva para executar o notebook completo?
**R:** Com subset de 10k amostras: ~5-10 minutos. Com dataset completo (70k): ~30-60 minutos.

### P: Preciso de GPU para rodar?
**R:** NÃ£o! Este projeto roda perfeitamente em CPU. PCA e K-Means do scikit-learn sÃ£o otimizados para CPU.

### P: Posso usar este cÃ³digo comercialmente?
**R:** Sim, sob os termos da licenÃ§a MIT. AtribuiÃ§Ã£o Ã© apreciada mas nÃ£o obrigatÃ³ria.

### P: Como salvo o notebook com os outputs?
**R:** File â†’ Download as â†’ Notebook (.ipynb) ou use `File â†’ Save and Checkpoint`

### P: Posso rodar no Google Colab?
**R:** Sim! FaÃ§a upload do `.ipynb` para o Colab. As dependÃªncias jÃ¡ estÃ£o instaladas no Colab.

### P: O que fazer se o kernel morrer com dataset completo?
**R:** Reduza o subset ou aumente a RAM. Ou use Colab (oferece mais memÃ³ria gratuitamente).

---

## ğŸ“ Suporte

Encontrou algum problema?

1. **Verifique a seÃ§Ã£o "SoluÃ§Ã£o de Problemas"** acima
2. **Abra uma Issue** no GitHub com detalhes:
   - Sistema operacional
   - VersÃ£o do Python
   - Mensagem de erro completa
   - Passos para reproduzir o problema

---

## ğŸ“ Para Estudantes

Este projeto Ã© ideal para:
- ğŸ“š Trabalhos acadÃªmicos de Machine Learning
- ğŸ¯ PortfÃ³lio de Data Science
- ğŸ”¬ Aprendizado prÃ¡tico de clustering
- ğŸ“Š CompreensÃ£o de reduÃ§Ã£o dimensional

**SugestÃµes de ExtensÃµes para TCC/Projetos:**
1. Comparar com redes neurais (CNN para classificaÃ§Ã£o)
2. Implementar sistema de reconhecimento em tempo real
3. Analisar outros datasets (Fashion-MNIST, EMNIST)
4. Desenvolver aplicaÃ§Ã£o web com Flask/Streamlit

---

<div align="center">

### â­ Se este projeto foi Ãºtil, considere dar uma estrela no GitHub!

**Feito com â¤ï¸ e â˜• por Tavs Coelho**

ğŸ“… Ãšltima atualizaÃ§Ã£o: Dezembro 2025

</div>
